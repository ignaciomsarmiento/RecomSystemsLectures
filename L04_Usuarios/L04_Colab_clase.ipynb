{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"../banner.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtrado Colaborativo Basado en Usuarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ignaciomsarmiento/RecomSystemsLectures/blob/main/L04_Usuarios/L04_Colab_clase.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este *cuaderno* trata sobre filtrado colaborativo basado en usuarios. El objetivo del *cuaderno* es que usted obtenga una visión general del problema predictivo de los sistemas de recomendación que utilizan filtrado colaborativo basado en usuario, aprenda distintos algoritmos que lo implementan, y que sea capaz de reconocer sus características, funcionamiento, y  desarrollarlos en `Python`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción: el problema de predicción \n",
    "\n",
    "Para entender un poco mejor cuál es el problema al que nos enfrentamos, supongamos que tenemos una matriz con $m$ usuarios y $n$ ítems. En esta matriz cada fila representa un usuario y cada columna un ítem. El valor de la celda denota el rating que le dió cada usuario al ítem. Este valor lo denotamos como $r_{ij}$ que será entonces el rating que le dio el usuario $i$ al ítem $j$. Un ejemplo de esta matriz sería la siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  style=\"max-width: 40%;\">\n",
    "<img src = \"figs/fig1.png\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta matriz tiene 7 usuarios ($m=7$) y 6 ítems ($n=6$). El usuario 1 le otorgó al ítem 1 un rating de 4, por lo tanto $r_{11}=4$. Sin embargo, no todos los usuarios calificaron/utilizaron todos los ítems y por lo tanto no todos tienen ranking. En el caso del usuario 1 este no utilizó los ítems 3, 4, y 6; por lo tanto aparecen con un signo de interrogación. Estos datos están faltando en la matriz.\n",
    "\n",
    "\n",
    "Consideremos otro ejemplo más concreto. Imaginemos que somos una compañía como Netflix y tenemos un repositorio de 20.000 películas y 5.000 usuarios. Tenemos además un sistema que registra la calificación que cada usuario le otorga a una película en particular. Es decir, tenemos una  matriz de tamaño 5,000 × 20,000. Sin embargo, es muy probable que los usuarios sólo habrán visto sólo una fracción de las películas (difícilmente todos vieron 20.000 películas!). Por lo tanto, la matriz será poco densa, la mayoría de las entradas en la matriz estarán vacías.\n",
    "\n",
    "\n",
    "El problema de predicción, tiene por objetivo predecir estos valores faltantes utilizando toda la información que tenemos a disposición: las calificaciones registradas, datos sobre películas, datos sobre usuarios, etc. Si el sistema es capaz de predecir con precisión los valores que faltan, podrá dar excelentes recomendaciones. Por ejemplo, si el usuario $i$ no ha utilizado el ítem $j$, pero nuestro sistema predice una calificación muy alta, es entonces muy probable que le guste $j$ si lo descubre a través del sistema de recomendación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ilustrar cómo construir e implementar este tipo de sistema de recomendación utilizaremos nuevamente los datos de  [MovieLens](https://grouplens.org/datasets/movielens/latest/) provista abiertamente por [grouplens](https://grouplens.org/about/what-is-grouplens/) para: **\"avanzar la teoría y la práctica de la computación social mediante la construcción y la comprensión de sistemas *(de recomendación)* utilizados por personas reales\".**\n",
    "\n",
    "Esta versión de los datos contiene varias bases con información de los usuarios, de las películas, y de los ratings. Tendremos que combinar estas bases para obtener una matriz similar a la ilustrada en la gráfica anterior. Carguemos entonces las librerías y los datos de usuarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos las librerías a utilizar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Cargamos los datos de los usuarios\n",
    "u_cols = ['user_id', 'edad', 'genero', 'ocupacion', 'codigo_postal']\n",
    "\n",
    "users = pd.read_csv('data/u.user', sep='|', names=u_cols,\n",
    " encoding='latin-1')\n",
    "\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que esta base contiene un identificador de usuario, su edad, género, ocupación, y el código postal donde viven. Luego cargamos la base de películas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos de las películas\n",
    "i_cols = ['movie_id','titulo', 'fecha_estreno', 'fecha_estreno_video', 'URL_IMDb', 'desconocido', 'Accion', 'Aventura',\n",
    "  'Animacion', 'Infantil', 'Comedia', 'Crimen', 'Documental', 'Drama', 'Fantasia',\n",
    "  'Cine-Noir', 'Horror', 'Musical', 'Misterio', 'Romance', 'Ciencia_ficcipn', 'Thriller', 'Guerra', 'Western']\n",
    "\n",
    "movies = pd.read_csv('data/u.item', sep='|', names=i_cols, encoding='latin-1')\n",
    "\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta base contiene un identificador de película, el título, cuándo fue estrenada en el cine, cuándo fue estrenada en video, la dirección web a IMDb, y el género al que pertenece, incluyendo una columna que marca como desconocido si el género no pertenece a ninguna de las restantes. Notemos además que una película puede pertenecer a varios géneros, por ejemplo: Toy Story pertenece  al genero Animación e Infantil. Pero por ahora nos importa sólo el identificador y el título de la película, por lo que nos quedamos con estas columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## completar, ayuda columnas de interes 'movie_id', 'titulo'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La última base que necesitamos cargar es la de ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos de los ratings \n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "\n",
    "ratings = pd.read_csv('data/u.data', sep='\\t', names=r_cols,\n",
    " encoding='latin-1')\n",
    "\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta base tiene información sobre qué `rating` el usuario (`user_id`) le otorgó a cada película (`movie_id`), e información de cuándo fue que hizo tal calificación (`timestamp`). Esta última columna no la utilizaremos por lo que la excluiremos de la base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitamos la columna timestamp \n",
    "# llenar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos elementos podemos construir la matriz que vincule usuarios, películas y ratings. Para ello usamos la función `pivot_table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Completar ayuda usar pivot_table siendo valores rating y las columnas movie_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## completar  saber la dimen con comando shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta matriz entonces vincula los usuarios con las películas. Las filas denotan los 943 usuarios y las columnas las 1682 películas en la base. El usuario 1 le otorgó a la película 1 un rating de 5, por lo tanto $r_{11}=5$. Al igual que en el ejemplo anterior, no todos los usuarios calificaron/vieron todas las películas y por lo tanto no todas tienen ranking. En el caso del usuario 1 este no calificó las películas 1673 a 1682 y por lo tanto aparecen con `NaN`; estos datos están faltando en la matriz.\n",
    "\n",
    "La tarea es entonces buscar estrategias para completar estos datos faltantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado colaborativo sencillo: medias, medias ponderadas, y datos demográficos.\n",
    "\n",
    "### Medias\n",
    "\n",
    "Comencemos por la estrategia quizás más simple e intuitiva para completar las celdas faltantes. Esta estrategia consiste en calcular el rating promedio que le asignó cada usuario que ranquearon esta película. No hacemos distinción entre los usuarios, y el rating de cada uno recibirá el mismo peso. Habrá casos donde ninguna de las películas ha sido ranqueeada, en tales situaciones le pondremos un rating default de 3. \n",
    "\n",
    "Para evaluar además la performance de esta estrategia, dividiremos la base original en bases de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la función train_test_split \n",
    "from sklearn.model_selection import train_test_split\n",
    "   \n",
    "#Asignamos `X` como la base original de ratings e `y` el usuario \n",
    "   \n",
    "## completar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y definiremos como métrica el error cuadrático medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la función mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Creamos una funcion que calcula la raíz del error cuadrático medio (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la base lista podemos construir nuestra función recomendadora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construir funcion de media\n",
    "## llenar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos entonces evaluar el RMSE que obtendremos de la base de prueba de haber entrenado la función recomendadora en la base de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear funcion Score modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos esta función y obtenemos el RMSE de este modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## aplicar funcion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos entonces utlizar este resultado como una base para la comparación a los modelos subsiguientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medias ponderadas\n",
    "\n",
    "En el modelo anterior, asignamos el mismo peso a todos los usuarios. Sin embargo, podríamos pensar que obtendríamos mejores recomendaciones si estas se generan a partir de usuarios similares. En este caso generaremos recomendaciones dando mayor peso a usuarios cuyas calificaciones son más similares a las del usuario que queremos generar la recomendación. \n",
    "\n",
    "Entonces alteraremos el modelo anterior teniendo en cuenta estas consideraciones. Esta estrategia sugiere que deberíamos ponderar más ciertos rankings, la pregunta natural que surge es cómo construimos estos pesos. En este caso el peso va a estar dado por cuán similares sean las calificaciones. Matemáticamente:\n",
    "\n",
    "$$\n",
    "r_{um}=\\frac{\\sum_{u',u'\\neq u}sim(u,u').r_{u'm}}{\\sum_{u',u'\\neq u}sim(u,u')}\n",
    "$$\n",
    "\n",
    "\n",
    "Es decir la predicción del rating del usuario $u$ para la película $m$, $r_{um}$, es la suma ponderada de los ratings de los otros usuarios ($u'$) a esta película, ponderado por cuán similares son los usuarios $u'$ a $u$. La pregunta que surge aquí es qué medida de similitud utilizar. En este ejercicio utilizaremos la distancia de coseno.\n",
    "\n",
    "#### Distancia de coseno\n",
    "\n",
    "Existen múltiples medidas de distancia que se utilizan para medir la similitud. En el *cuaderno: Introducción al Análisis de Clusters* describimos varias de estas medidas que también pueden ser utilizadas en este contexto. Sin embargo, existen otras, como la distancia de coseno, que suele ser la más utilizada en los sistemas de recomendación.\n",
    "\n",
    "Matemáticamente esta se define como: \n",
    "\n",
    "$$\n",
    "coseno(x,y)=\\frac{x.y'}{|x||y|}\n",
    "$$\n",
    "\n",
    "Es decir, es el cociente del producto punto, dividido por las normas de los vectores. Esto hace que la medida esté entre -1 y 1. Geométricamente esta medida es el coseno entre el ángulo de los dos vectores en el espacio. En la figura a continuación la medida de distancia estará entonces definida por el coseno del ángulo $\\theta$:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src = \"figs/dist_cos.png\" alt = \"coseno\" style = \"width: 300px;\"/>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando el coseno es igual a 1 o el ángulo es 0, los vectores son exactamente similares. Por el otro, si el coseno da -1, el ángulo es de 180 grados, esto nos denota que dos vectores son exactamente disimilares. \n",
    "\n",
    "Notemos que, si dos vectores, $x$ e $y$, tienen media cero, el coseno del angulo entre ambos coincidirá con el coeficiente de correlación de Pearson que estudiamos en el *cuaderno: Introducción al Análisis de Clusters*.\n",
    "\n",
    "**¿Qué medida de similitud elegir?** La elección de la medida de similaridad a utilizar depende del caso de estudio. Por ejemplo, en caso que las magnitudes sean importantes, la distancia euclideana es una medida apropiada para utilizar. Pero si la correlación es lo que importa, entonces la correlación de Pearson o el coseno son más apropiadas. Por otro lado si la popularidad del ítem bajo estudio es importante, entonces el producto escalar será una medida adecuada. Puesto que si los ítems aparecen con mucha frecuencia (por ejemplo, videos populares de YouTube) estos tienden a normas grandes y el producto escalar capturará mejor esta información. Sin embargo, si no somos cuidadosos, aquellos artículos populares terminarán siendo los más recomendados. En casos como este, podemos pensar en definir una medida que \"regularice\" las normas, como por ejemplo: $similitud(x,y)=|x|^\\alpha  |y|^\\alpha cos(x,y)$ para algún $\\alpha\\in(0,1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementación\n",
    "Completado este breve desvío, estamos en condiciones de implementar nuestro recomendador basado en medias ponderadas. Comenzamos primero imputando 0 a los valores faltantes. Esto lo hacemos para poder calcular la similitud de coseno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenamos los faltantes con 0\n",
    "r_matrix_dummy = r_matrix.copy().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto estamos en condiciones de usar la función `cosine_similarity` que va a calcular la similitud de coseno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos cosine_similarity \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#Completar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos entonces como resultado una matriz que muestra la similitud de coseno entre los diferentes usuarios. La matriz diagonal que muestra $1$ nos dice que la similitud entre el usuario 1 y sí mismo es 1. Note que el 0.16 dice que la similitud entre 1 y 2 es de 0.16. En este caso, dado que estamos evaluando ratings positivos, esta matriz retornará entradas positivas.\n",
    "\n",
    "Con esta matriz calculada podemos entonces utilizarla para construir nuestra función recomendadora basada en medias ponderadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Completar\n",
    "#Crear función recomendadora basada en medias con input user_id y movie_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos en condiciones entonces de evaluar este modelo con la función antes creada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score(cf_user_wmean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que esta simple \"sofisticación\" mejora el desempeño predictivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos demográficos de los usuarios\n",
    "\n",
    "El modelo anterior entonces incorporó  similitud entre las calificaciones de los usuarios para mejorar las recomendaciones. ¿Qué sucede entonces si utilizamos variables demográficas? La intuición es que individuos de similares géneros, profesiones, edades, etc., tendrán preferencias más similares que individuos con características demográficas diferentes.\n",
    "\n",
    "En este caso lo que haremos es restringir a los ratings de individuos con las mismas características demográficas, en jerga estadística, utilizaremos un modelo de medias condicionales.\n",
    "\n",
    "Para ello, primero unimos los datos originales sobre usuarios con nuestra base de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(X_train, users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta base que tiene ahora variables demográficas podemos intentar mejorar nuestro recomendador. Ilustremos entonces una función recomendadora basada en género y ocupación. Para ello, primero calculamos el rating promedio por género y ocupación. En `pandas` esto es relativamente sencillo utilizando la función `groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.set_index('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el rating promedio basado en género y ocupación\n",
    "# Completar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos entonces el promedio de rating por género y ocupación. Así, los administradores femeninos ranquearon la película 1 con un promedio de 3.93 y los masculinos con 3.75. Mientras que los artistas no ranquearon la película 2. Con esta información generamos una función recomendadora que incorpore esta información y en los casos donde no tenemos información utilizaremos el rating 3 como default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Completar función recomendadora que incorpore la información anterior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos entonces esta función recomendadora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score(cf_gen_occ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que esta función es la que peor funciona de las antes evaluadas. La función que incorporaba el coseno como medida de similitud lograba mejores recomendaciones. En la sección siguiente nos centraremos en entender mejor las medidas de similitud y cómo estas nos permiten mejorar los recomendadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado colaborativo basado en *embeddings*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos anteriormente parte del problema reside en encontrar productos similares para recomendar. Una forma de lograrlo es incrustar (*embed*) los ítems, películas, en un espacio de baja dimensión.  *Embedding* o incrustación implica entonces un mapeo de un conjunto discreto (el conjunto de elementos a recomendar) a un espacio vectorial llamado típicamente de menor dimensión a un espacio vectorial, llamado *embedding space* o *espacio de incrustación*. \n",
    "\n",
    "Es decir, el sistema de recomendación mapea cada ítem, película, a un *embedding* vector en un *embedding space* común. Típicamente, este espacio, es de baja dimensión, considerablemente menor al tamaño del espacio original, y captura alguna estructura latente de los elementos. Así, elementos similares, como los videos de YouTube que suele ver el mismo usuario, terminan juntos en el mismo *embedding space* y la noción de \"cercanía\" se define por una medida de similitud.\n",
    "\n",
    "Antes de describir cómo podemos generar estos *embeddings*, exploremos qué son los *embeddings* y el tipo de cualidades que queremos que tengan y como determinarlos a partir de los datos.\n",
    "\n",
    "Supondremos, por simplicidad, que la matriz de ratings es binaria; es decir que un valor de 1 indica interés en la película. El objetivo de nuestro recomendador es que cuando un usuario visite la página de inicio, el sistema debería recomendar películas basándose tanto en la similitud con películas que le han gustado al usuario en el pasado como con películas que les gustaron a usuarios similares. \n",
    "\n",
    "Para ilustrar, imaginemos que tenemos sólo 5 películas, descriptas en la siguiente tabla:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                **Película**               | **Clasificación** |                                                                                                  **Descripción**                                                                                                  |\n",
    "|:-----------------------------------------:|:-----------------:|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|\n",
    "| Batman: El caballero de la noche asciende |       PG-13       |                              Batman se esfuerza por salvar a Gotham City de la aniquilación nuclear en esta secuela del Caballero de la Noche ambientada en el universo de DC Comics.                             |\n",
    "|     Harry Potter y la Piedra Filosofal    |         PG        |                       Un niño huérfano descubre que es un mago y se matricula en el Colegio Hogwarts de Magia y Hechicería donde libra su primera batalla contra el malvado Lord Voldemort.                       |\n",
    "|                   Shrek                   |         PG        |                                Un ogro adorable y su compañero burro se embarcan en una misión para rescatar a la princesa Fiona que está encarcelada en su castillo por un dragón.                               |\n",
    "|        Las trillizas de Belleville        |       PG-13       | Cuando el ciclista profesional Champion es secuestrado durante el Tour de Francia, su abuela y su perro con sobrepeso viajan al extranjero para rescatarlo con la ayuda de un trío de ancianos cantantes de jazz. |\n",
    "|                  Memento                  |         R         |                                                       Un amnésico busca desesperadamente resolver el asesinato de su esposa tatuándose pistas en su cuerpo.                                                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embembedding o incrustación en una (1) dimensión**\n",
    "\n",
    "\n",
    "Comencemos suponiendo que queremos ordenar las películas arriba mencionadas a lo largo del segmento $[-1,1]$ de forma tal que películas similares estén más cerca que de películas menos similares. \n",
    "\n",
    "Uno de estos posibles ordenamientos es asignar un escalar que describa si la película es para niños o adultos. El escalar va a asignar valores negativos si la película es para niños y positivos si es para adultos. La figura a continuación muestra este posible ordenamiento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src = \"figs/colab1.png\" alt = \"embedding1D\" style = \"width: 500px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La figura muestra que Shrek que es para niños esta más cercana a -1, y Memento, que es para adultos, está más cercana a 1. De forma similar, tenemos 4 individuos que se ubicarán más cerca de -1 si prefieren películas de niños y a 1 si prefieren películas para adultos. \n",
    "\n",
    "De forma similar podríamos mapear a los usuarios dependiendo de sus preferencias por películas para niños o para adultos. Así el ordenamiento resultante podríamos representarlo en la siguiente figura:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src = \"figs/colab2.png\" alt = \"embedding1D\" style = \"width: 500px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente, en la figura de abajo, tenemos una matriz que une usuarios con las película que ha visto. Particularmente notemos que el tercer usuario sólo ve películas para niños y el cuarto sólo para adultos. Por lo que recomendaciones basados en esta única dimensión funcionaría muy bien para estos usuarios, pero no tanto para el primer y segundo usuario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src = \"figs/colab3.png\" alt = \"embedding1D\" style = \"width: 500px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, si bien este *embedding* ayuda a capturar cuánto está orientada la película hacia los niños en comparación con los adultos, hay otros aspectos de una película que queremos capturar y que ayudarían a mejorar las recomendacioens. Continuando con el ejemplo, agreguemos una segunda dimensión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embembedding o incrustación en dos (2) dimensiones**\n",
    "\n",
    "Dados los resultados anteriores, una característica no es suficiente para explicar las preferencias de todos los usuarios, tratemos entonces agregando una segunda característica. \n",
    "\n",
    "Supongamos que agregamos como dimensión la popularidad de película, mediada como el grado en que cada película es un éxito de taquilla o una película independiente y de culto. En este caso el escalar nuevamente estará entre $[-1,1]$ y tomará -1 si es cine de culto y 1 si es un éxito de taquilla. \n",
    "\n",
    "Con esta segunda característica, podemos ubicar las películas en un espacio bidimensional: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src = \"figs/colab4.png\" alt = \"embedding2D\" style = \"width: 500px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este *embedding space* bidimensional, podemos definir una distancia entre películas tal que las películas están cerca (y por lo tanto se infiere que son similares) si ambas son similares en la dimensión en que están dirigidas a niños versus adultos, así como en la medida en que son películas de gran éxito frente a películas de independientes y de culto. Estas, por supuesto, son sólo dos de las muchas características de las películas que pueden ser importantes.\n",
    "\n",
    "De manera más general, lo que estamos haciendo es mapear las películas a un *embedding space* o *espacio incrustado*. En este espacio cada película se describe mediante un conjunto de coordenadas. Por ejemplo, en este espacio, \"Shrek\" tiene las coordenadas  (-1,0, 0,95) y \"Memento\" (1, -0,5). En general, cuando mapeamos a un espacio $d-dimensional$, cada película se representa mediante $d$ números con valores reales, cada uno de los cuales da la coordenada en una dimensión.\n",
    "\n",
    "De la misma forma, podemos ubicar a los individuos en este espacio:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src = \"figs/colab5.png\" alt = \"embedding2D\" style = \"width: 500px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este *embeddings*, volvamos a evaluar el problema de recomendar. Tenemos nuevamente la matriz de las películas que los individuos vieron o no y los *embeddings* generados anteriormente. Entonces para la película de Harry Potter tenemos (0.9,-0.2) donde 0.9 corresponde a la ubicación en la dimensión \"taquilla\" y el -0.2 en la dimensión \"niño-adulto\". \n",
    "\n",
    "El objetivo entonces será en combinar estos *embeddings* de forma tal de generar una recomendación, en este ejemplo buscaremos evaluar si recomendaremos Shrek al usuario 4 que no la ha visto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src = \"figs/colab6.png\" alt = \"embedding2D\" style = \"width: 500px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En estos ejemplos, diseñamos a mano los *embeddings* y nombramos estas dimensiones. En la práctica, los *embeddings*  se pueden generar automáticamente, que es el poder de los modelos de filtrado colaborativo. En estos casos más generales y automáticos donde se genera el *embedding space* las dimensiones individuales no tienen un nombre. En ocasiones, podemos inspeccionar los *embeddings* y asignarle una interpretación. Pero generalmente esto no será posible ya que estarán capturando una dimensión latente, ya que no representa una característica no explícita en los datos sino que se deduce de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorización de matrices\n",
    "\n",
    "Luego de la introducción a los *embedding spaces* y medidas de similitud veamos cómo  generar estos espacios. La factorización de matrices es un modelo simple que nos permite generar estos *embeddings*.\n",
    "\n",
    "Dada la matriz $A\\in\\mathbb{R}^{ m\\times n}$ con $m$ usuarios y $n$ ítems, buscaremos que el modelo genere:\n",
    "\n",
    "- Una matriz de *embeddings* de usuarios $U\\in\\mathbb{R}^{ m\\times d}$ donde la fila $i$ es el *embedding* del usuario $i$.\n",
    "- Una matriz de *embeddings* de elementos $V\\in\\mathbb{R}^{ n\\times d}$, donde la fila $j$ es el *embedding* del elemento $j$.\n",
    "\n",
    "Los *embeddings* se generaran de forma tal que el producto $UV^T$ sea una buena representación de la matriz $A$. Volviendo al ejemplo anterior, $U$ estará dado por:\n",
    "\n",
    "$$\n",
    "U=\\left(\\begin{array}{cc}\n",
    "1 & .1\\\\\n",
    "-1 & 0\\\\\n",
    ".2 & -1\\\\\n",
    ".1 & 1\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "y $V$ estará dada por \n",
    "\n",
    "$$\n",
    "V=\\left(\\begin{array}{cc}\n",
    ".9 & -.2\\\\\n",
    "-.8 & -.8\\\\\n",
    "1 & -1\\\\\n",
    "1 & .9\\\\\n",
    "-.9 & 1\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "De forma tal que el producto aproxime de la matriz que indica que pelicula ha visto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src = \"figs/colab7.png\" alt = \"embedding2D\" style = \"width: 500px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos libreria numpy\n",
    "import numpy as np\n",
    "#Completar creación de matriz y matriz transpuesta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer producto punto entre ambas matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que esta generación es similar a la descomposición de matrices que estudiamos en el *cuaderno: Descomposición en Valores Singulares. Fundamentos Teóricos*. Al factorizar estamos buscando una  representación más compacta que aprender la matriz completa. Particularmente, la matriz completa tiene $O(nm)$ entradas, mientras que las matriz de *embeddings*,  $U$ y $V$ tienen $O((n+m)d)$ entradas, donde la dimensión $d$ suele ser mucho más pequeña que $m$ y $n$.\n",
    "\n",
    "Como resultado, la factorización de matrices encuentra una estructura latente en los datos, asumiendo que las observaciones se encuentran cerca de un subespacio de baja dimensión. En el ejemplo anterior, los valores de $n$, $m$ y $d$ son tan pequeño que la ventaja es insignificante. Sin embargo, en los sistemas de recomendación reales, la factorización de matrices puede ser significativamente más compacta que aprender la matriz completa, como vimos con la reducción de dimensión de las imágenes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factorización de matrices con SVD\n",
    "\n",
    "\n",
    "La factorización de matrices consiste en descomponer una matriz en el producto de múltiples matrices. Como estudiamos en el *cuaderno: Descomposición en Valores Singulares. Fundamentos Teóricos* esto se puede hacer a través de la Descomposición en Valores Singulares (SVD).\n",
    "\n",
    "En este caso lo que va a hacer SVD es descomponer la matriz de ratings $A$ en la mejor representación de menor dimensión de esta matriz. Matemáticamente estamos buscando descomponer $A$, la matriz de calificaciones, en:\n",
    "\n",
    "$$\n",
    "A = U\\Sigma V'\n",
    "$$\n",
    "\n",
    "$U$ es entonces la matriz de *embeddings* de usuarios, $V$ la  matriz de *embeddings* de películas, y $\\Sigma$ es una matriz diagonal singular que contiene los valores singulares, que podemos pensarlos con los ponderadores. Podemos también pensar a $U$  como la representación de cuánto le \"gusta\" a los usuarios cada característica de la película y $V^{T}$ representa cuán relevante es cada característica a la película. \n",
    "\n",
    "Para obtener una representación de rango menor, tomamos estas matrices y sólo conservamos aquellas $k$ características que pensamos representan mejor los gustos y las preferencias de los usuarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementación en `Python`\n",
    "\n",
    "Implementemos esta estrategia en `Python`, para ello primero necesitamos transformar los valores no observados de la matriz de ratings en 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Completar\n",
    "## Crear pivot table de ratings con filas de usuarios y columnas los ids de peliculas con valores de ratings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos nuevamente un dataframe con los usuarios en las filas y las películas en la columnas. Necesitamos ahora transformarlas a una matriz y centrar en cero utilizando la media de los ratings de cada usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Completar\n",
    "## Realizar media de rating de una pelicula segun los usuarios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos ahora en posición de realizar la SVD. En el *cuaderno: Descomposición en Valores Singulares. Fundamentos Teóricos* utilizamos [Numpy](https://numpy.org/) en nuestros ejemplos, en este cuaderno usarmeos [SciPy](https://scipy.org/) y los invito a que prueben utilizando [Numpy](https://numpy.org/).\n",
    "\n",
    "La ventaja de [SciPy](https://scipy.org/) es que permite elegir los valores singulares como argumento de la función en vez de tener que truncar la matriz posteriormente. \n",
    "\n",
    "En este ejemplo, utilizaremos 50 para ilustrar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "# Completar SVD usando como parametro 50 valores singulares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar nuestra recomendación tenemos que reconstruir la matriz $A$ con esta aproximación menor. Es decir tenermos que multiplicar $U$, $\\Sigma$, and $V^{T}$ para obtener la aproximación de rango $k=50$ de $A$. Puesto que centramos en cero los ratings, necesitamos agregarlos nuevamente.\n",
    "\n",
    "Haciendo esto tenemos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Completar\n",
    "#Recrear la base de recomendaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que eligimos $k=50$ de forma arbitraria. Si queremos optimizar este recomendador, tendríamos que proceder de forma similar a cómo lo hicimos al inicio de este *cuaderno*, dividir la muestra en entrenamiento y prueba, y buscar el número $k$ que minimize el RMSE. Los invito a que lo hagan por su cuenta y comparen los resultados con los recomendadores que construimos anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Recomendando películas.\n",
    "\n",
    "Con la matriz de recomendaciones podemos construir una función que genere recomendaciones a cualquier usuario.\n",
    "\n",
    "Esta función generará recomendaciones de películas para un usuario específico de forma tal que omita a aquellas que ya ha ranqueado. Estamos asumiendo que si la calificó es porque ya la vió, pero como comparación retornaremos por separado aquellas películas ya calificadas.\n",
    "\n",
    "Comenzamos poniendo las recomendaciones en un dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recomendac_df = pd.DataFrame(db_recomendaciones, columns = r_matrix.columns)\n",
    "recomendac_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este data frame armamos nuestra función recomendadora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Completar\n",
    "#Crear función de recomendador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que la función toma como argumentos la base que construimos de recomendaciones predichas, el número de usuario, la base de películas y el número de películas que queremos que recomiende.\n",
    "\n",
    "Notemos que agregamos la base de películas a la función para poder incluir características explícitas de las películas, aunque no las utilizamos en la generación de los *embeddings* y por lo tanto en la recomendación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calificadas, recomendaciones = recomendador(recomendac_df, 837, movies, ratings, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos entonces las recomendaciones generadas. El usuario 837, ha calificado 46 películas, entre las 10 en su tope tiene películas de romance com 'Jane Eyre' e infantiles como 'Willy Wonka and the Chocolate Factory':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calificadas.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos las recomendaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recomendaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En estas recomendaciones aparecen películas de romance como \"Il Postino\" e infantiles como \"Toy Story\". Estas parecen ser recomendaciones bastante buenas. Notemos además que a pesar de que no incluimos el género como característica en la factorización, esta fue capaz de captar el *embedding* con esta dimensión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consideraciones finales\n",
    "\n",
    "En este *cuaderno* estudiamos distintos formas de construir filtrados colaborativos comenzando con formas sencillas de incorporar información de otros usuarios hasta capturar características latentes con factorización de matrices.\n",
    "\n",
    "Sin embargo, al factorizar las matrices y reducir su dimensión hay que tener en cuenta que es probable que se esté perdiendo parte de las señales. También que considerar que cuando las matrices son poco densas, es decir, las entradas estan faltantes, la solución de SVD estará cercana a cero, produciendo recomendaciones poco eficientes.\n",
    "\n",
    "\n",
    "En casos como estos se suele utilizar  **factorización matricial ponderada**:\n",
    "\n",
    "$$\n",
    "\\min_{U\\in\\mathbb{R}^{m\\times d}, V\\in\\mathbb{R}^{n\\times d}} \\sum_{(i,j)\\in obs}(A_{i,j} - \\langle U_i, V_j \\rangle)^2 + \\omega_0 \\sum_{(i,j)\\not\\in obs} (\\langle U_i, V_j \\rangle)^2\n",
    "$$\n",
    "\n",
    "Esta descompone la función objetivo en dos sumas:\n",
    "\n",
    "- Una suma sobre las entradas observadas.\n",
    "- Una suma sobre entradas no observadas (tratadas como ceros).\n",
    "\n",
    "donde, $\\omega_0$ es un hiperparámetro que pondera los dos términos para que la función objetivo no esté dominada por uno u otro componente. En estos casos, será clave ajustar correctamente este hiperparámetro.\n",
    "\n",
    "En ocaciones, cuando hay  ítems muy frecuentes o populares que pueden dominar la función objetivo se suele ponderar por la frecuencia de los elementos. En otras palabras, podemos reemplazar la función objetivo por:\n",
    "\n",
    "$$\\sum_{(i,j)\\in obs}\\omega_{i,j} (A_{i,j} - \\langle U_i, V_j \\rangle)^2 + \\omega_0 \\sum_{(i,j)\\not\\in obs} (\\langle U_i, V_j \\rangle)^2$$\n",
    "\n",
    "Donde $\\omega_{i,j}$ es una función de la frecuencia de ocurrencia.\n",
    "\n",
    "\n",
    "Si bien la **factorización matricial ponderada** puede ser extremadamente útil, es material para otro curso.\n",
    "\n",
    "Finalmente, es importante notar que cuando factorizamos matrices incorporamos factores latentes no sólo de los usuarios sino también de las películas, los ítems. En el cuaderno siguiente veremos cómo utilizar sólo información de los ítems *Filtrado Colaborativo Basado en Items: Análisis de Canasta de Compra.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "\n",
    "- Banik, R. (2018). Hands-on recommendation systems with Python: start building powerful and personalized, recommendation engines with Python. Packt Publishing Ltd.\n",
    "\n",
    "- Covington, P., Adams, J., & Sargin, E. (2016). Deep Neural Networks for YouTube recommendations. Proceedings of the 10th ACM Conference on Recommender Systems. https://doi.org/10.1145/2959100.2959190 \n",
    "\n",
    "- Google developers. (n.d.). Recommendation systems. Google. Consultado en Abril 3, 2022. Disponible en https://developers.google.com/machine-learning/recommendation/overview \n",
    "\n",
    "- Google developers. (n.d.). Embeddings: Motivation From Collaborative Filtering. Consultado en Mayo 13, 2022. Disponible en  https://developers.google.com/machine-learning/crash-course/embeddings/motivation-from-collaborative-filtering\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe36d3cf18f454bb22b210d1ce52ae8c21a1b2f0a9257a143474ae90bef14b60"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
